{
   "cells": [
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "# Dataset Creation\n",
            "\n",
            "Dans ce notebook, nous allons entrainer le premier modèle nécessaire à la création de notre outil de réduction de la difficulté."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 1,
         "metadata": {},
         "outputs": [],
         "source": [
            "\n",
            "# ---------------------------- PREPARING NOTEBOOK ---------------------------- #\n",
            "# Autoreload\n",
            "%load_ext autoreload\n",
            "%autoreload 2\n",
            "\n",
            "# Random seed\n",
            "import numpy as np\n",
            "np.random.seed(42)\n",
            "\n",
            "# External modules\n",
            "import os\n",
            "from IPython.display import display\n",
            "\n",
            "# Set global log level\n",
            "import logging\n",
            "logging.basicConfig(level=logging.INFO)\n",
            "os.environ['TOKENIZERS_PARALLELISM'] = 'false'\n",
            "\n",
            "# Define PWD as the current git repository\n",
            "import git\n",
            "repo = git.Repo('.', search_parent_directories=True)\n",
            "pwd = repo.working_dir\n",
            "\n",
            "# import"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 2,
         "metadata": {},
         "outputs": [],
         "source": [
            "MODEL = \"bofenghuang/vigostral-7b-chat\"\n",
            "# import"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## $N$ simpler sentences\n",
            "\n",
            "Dans un premier temps, nous allons demander à MISTRAL de nous générer $N$ variations simplifiée d'une phrase donnée. Pour ce faire, nous allons d'abord créer un jeu de donnée très simple, composé de phrases et de leurs simplifications qui seront utilisées pour fine-tuner le modèle. Pour nous aider dans la création de ce jeu de donnée, nous allons utiliser GPT-4, sans aucun fine-tuning, pour générer des simplifications de phrases."
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### GPT-4 Fine-tuning Dataset\n",
            "\n",
            "Pour créer notre premier jeu de donnée que nous appelerons `Fine-tuning dataset` par la suite, nous allons utiliser la prompt suivante avec le modèle GPT-4 :\n",
            "\n",
            "```mkd\n",
            "Dans le contexte d'un travail de recherche, je souhaite obtenir 5 exemples de simplifications d'une phrase donnée en français. Invente 6 phrases de niveau de difficulté CECRL respectifs A2, B1, B2, C1 et C2. Chaque phrase doit parler d'un sujet différent. Tu dois ensuite simplifier chacune de ces phrases en diminuant son niveau CECRL de 1 cran. Voici un exemple de simplification depuis le niveau C2 vers le niveau C1.\n",
            "\n",
            "---\n",
            "Phrase à simplifier de niveau CECRL C2 : 'Alors qu'au cours du Paléolithique, la diffusion avait fractionné l'écoumène en petits groupes, la tendance depuis la fin de la dernière glaciation est à l'épaississement des relations dans l'Ancien Monde, par augmentation des effectifs et par tissage d'interconnexions.'\n",
            "Phrase simplifiée de niveau CECRL C1 : 'Pendant le Paléolithique, la diffusion avait séparé la population en petits groupes. Depuis la fin de la dernière glaciation, les relations se sont renforcées dans l'Ancien Monde, avec plus de personnes et un réseau de connexions plus étroit.'\n",
            "---\n",
            "!!! Tu ne dois pas utiliser cet exemple pour ton travail. Tu dois inventer tes propres phrases. !!!\n",
            "\n",
            "Ton message doit être structuré de la manière suivante :\n",
            "---\n",
            "{Phrase de niveau CECRL A2} -> {Phrase simplifiée de niveau CECRL A1}\\n\n",
            "{Phrase de niveau CECRL B1} -> {Phrase simplifiée de niveau CECRL A2}\\n\n",
            "{Phrase de niveau CECRL B2} -> {Phrase simplifiée de niveau CECRL B1}\\n\n",
            "{Phrase de niveau CECRL C1} -> {Phrase simplifiée de niveau CECRL B2}\\n\n",
            "{Phrase de niveau CECRL C2} -> {Phrase simplifiée de niveau CECRL C1}\\n\n",
            "---\n",
            "!!! Tu ne dois écrire que les phrases inventées et les phrases simplifiées. Tu ne dois ajouter aucun commentaire. !!!\n",
            "```\n",
            "\n",
            "---\n",
            "Un jeu de donnée généré par GPT-4 est disponible dans le dossier `data/fine-tuning-dataset.csv`. Il est composé de 100 exemples de phrases et de leurs simplifications. Nous allons utiliser ce jeu de donnée pour fine-tuner notre modèle."
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### Download the dataset "
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 3,
         "metadata": {},
         "outputs": [],
         "source": [
            "# ----------------------- DOWNLOAD FINE-TUNING DATASET ----------------------- #\n",
            "import pandas as pd\n",
            "from huggingface_hub import snapshot_download\n",
            "\n",
            "\n",
            "def ft_download_data(data_name: str, pwd: str = None):\n",
            "    \"\"\"\n",
            "    Download the data from the HuggingFace Hub.\n",
            "\n",
            "    Args:\n",
            "        data_name (str): The name of the data to download.\n",
            "        pwd (str): The current working directory. Defaults to None.\n",
            "    \"\"\"\n",
            "    # Find PWD\n",
            "    if pwd is None:\n",
            "        repo = git.Repo(\".\", search_parent_directories=True)\n",
            "        pwd = repo.working_dir\n",
            "\n",
            "    # Determine the path\n",
            "    if data_name == \"sentence_simplification\":\n",
            "        path = os.path.join(pwd, \"data\", \"raw\")\n",
            "        if not os.path.exists(path):\n",
            "            os.makedirs(path)\n",
            "    elif data_name == \"Data\":\n",
            "        path = os.path.join(pwd, \"data\", \"raw\")\n",
            "        if not os.path.exists(path):\n",
            "            os.makedirs(path)\n",
            "    else:\n",
            "        raise ValueError(f\"The data {data_name} is not available.\")\n",
            "\n",
            "    # Download CSVs\n",
            "    snapshot_download(\n",
            "        repo_id=\"OloriBern/FLDE\",\n",
            "        allow_patterns=[f\"{data_name}/*.csv\"],\n",
            "        local_dir=path,\n",
            "        revision=\"main\",\n",
            "        repo_type=\"dataset\",\n",
            "    )\n",
            "\n",
            "    # Return csv paths (recursively)\n",
            "    csv_paths = [\n",
            "        os.path.join(path, data_name, file)\n",
            "        for file in os.listdir(os.path.join(path, data_name))\n",
            "        if file.endswith(\".csv\")\n",
            "    ]\n",
            "    return csv_paths\n",
            "\n",
            "\n",
            "def download_data(pwd: str = None):\n",
            "    csv_path = ft_download_data(\"sentence_simplification\", pwd)\n",
            "    data = pd.read_csv(\n",
            "        csv_path[0],\n",
            "        sep=\" -> \",\n",
            "        names=[\"Original sentence\", \"Simplified sentence\"],\n",
            "        header=None,\n",
            "    )\n",
            "\n",
            "    return data\n",
            "\n",
            "\n",
            "# import"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 4,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "application/vnd.jupyter.widget-view+json": {
                     "model_id": "e62ef3041a054019a02d4879ca26b47e",
                     "version_major": 2,
                     "version_minor": 0
                  },
                  "text/plain": [
                     "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
                  ]
               },
               "metadata": {},
               "output_type": "display_data"
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "/tmp/ipykernel_10404/441393833.py:51: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
                  "  data = pd.read_csv(\n"
               ]
            },
            {
               "data": {
                  "text/html": [
                     "<div>\n",
                     "<style scoped>\n",
                     "    .dataframe tbody tr th:only-of-type {\n",
                     "        vertical-align: middle;\n",
                     "    }\n",
                     "\n",
                     "    .dataframe tbody tr th {\n",
                     "        vertical-align: top;\n",
                     "    }\n",
                     "\n",
                     "    .dataframe thead th {\n",
                     "        text-align: right;\n",
                     "    }\n",
                     "</style>\n",
                     "<table border=\"1\" class=\"dataframe\">\n",
                     "  <thead>\n",
                     "    <tr style=\"text-align: right;\">\n",
                     "      <th></th>\n",
                     "      <th>Original sentence</th>\n",
                     "      <th>Simplified sentence</th>\n",
                     "    </tr>\n",
                     "  </thead>\n",
                     "  <tbody>\n",
                     "    <tr>\n",
                     "      <th>0</th>\n",
                     "      <td>L'apprentissage des langues étrangères stimule...</td>\n",
                     "      <td>On apprend mieux avec les langues étrangères.</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>1</th>\n",
                     "      <td>Les écosystèmes marins sont régulièrement pert...</td>\n",
                     "      <td>Les usines abîment souvent la vie sous la mer.</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>2</th>\n",
                     "      <td>L'absorption de polluants atmosphériques par l...</td>\n",
                     "      <td>Les forêts aident à garder l'air propre en abs...</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>3</th>\n",
                     "      <td>Confrontées à une mutation économique rapide, ...</td>\n",
                     "      <td>Les entreprises doivent changer vite pour rest...</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>4</th>\n",
                     "      <td>La philosophie existentialiste s'affirme par l...</td>\n",
                     "      <td>L'existentialisme dit que la vie n'a pas de se...</td>\n",
                     "    </tr>\n",
                     "  </tbody>\n",
                     "</table>\n",
                     "</div>"
                  ],
                  "text/plain": [
                     "                                   Original sentence  \\\n",
                     "0  L'apprentissage des langues étrangères stimule...   \n",
                     "1  Les écosystèmes marins sont régulièrement pert...   \n",
                     "2  L'absorption de polluants atmosphériques par l...   \n",
                     "3  Confrontées à une mutation économique rapide, ...   \n",
                     "4  La philosophie existentialiste s'affirme par l...   \n",
                     "\n",
                     "                                 Simplified sentence  \n",
                     "0      On apprend mieux avec les langues étrangères.  \n",
                     "1     Les usines abîment souvent la vie sous la mer.  \n",
                     "2  Les forêts aident à garder l'air propre en abs...  \n",
                     "3  Les entreprises doivent changer vite pour rest...  \n",
                     "4  L'existentialisme dit que la vie n'a pas de se...  "
                  ]
               },
               "execution_count": 4,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "df = download_data()\n",
            "df.head()"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### Download the tokenizer"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 5,
         "metadata": {},
         "outputs": [],
         "source": [
            "from transformers import AutoTokenizer\n",
            "\n",
            "\n",
            "def download_tokenizer(model_name: str = MODEL, training: bool = True):\n",
            "    # Download tokenizer\n",
            "    tokenizer = AutoTokenizer.from_pretrained(\n",
            "        model_name,\n",
            "        padding_side=\"left\",\n",
            "        truncation_side=\"left\",\n",
            "        add_eos_token=training,\n",
            "        add_bos_token=True,\n",
            "        trust_remote_code=True,\n",
            "    )\n",
            "    tokenizer.pad_token = tokenizer.eos_token\n",
            "\n",
            "    return tokenizer\n",
            "\n",
            "\n",
            "# import"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 6,
         "metadata": {},
         "outputs": [],
         "source": [
            "tokenizer = download_tokenizer()"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### Create the dataset"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 7,
         "metadata": {},
         "outputs": [],
         "source": [
            "# ------------------------------ CREATE DATASET ------------------------------ #\n",
            "from datasets import Dataset\n",
            "\n",
            "\n",
            "def format_data(\n",
            "    df: pd.DataFrame,\n",
            "    tokenizer: AutoTokenizer,\n",
            "    training: bool = True,\n",
            "):\n",
            "    # Create conversation\n",
            "    logging.info(\"Create conversation...\")\n",
            "\n",
            "    def create_conversation(row):\n",
            "        conversation = [\n",
            "            {\n",
            "                \"role\": \"system\",\n",
            "                \"content\": \"Vous êtes un modèle de langage naturel capable de simplifier des phrases en français. La phrase simplifiée doit avoir un sens aussi proche que possible de la phrase originale, mais elle est d'un niveau inférieur du CECRL et donc plus facile à comprendre. Par exemple, si une phrase est au niveau C1 du CECRL, simplifiez-la en B2. Si elle se situe au niveau B2, simplifiez-la en B1. Si elle se situe au niveau B1, simplifiez-la en A2. Si le niveau A2 est atteint, simplifiez en A1.\",\n",
            "            }\n",
            "        ]\n",
            "        if training:\n",
            "            conversation.extend(\n",
            "                [\n",
            "                    {\n",
            "                        \"role\": \"user\",\n",
            "                        \"content\": f\"\"\"Voici une phrase en français de niveau CECRL {['A2', 'B1', 'B2', 'C1', 'C2'][row['index'] % 5]} à simplifier :\n",
            "                    \\\"\\\"\\\"{row['Original sentence']}\\\"\\\"\\\"\n",
            "                    Donne moi une phrase simplifiée au niveau CECRL {['A1', 'A2', 'B1', 'B2', 'C1'][row['index'] % 5]} tout en conservant au maximum son sens original\n",
            "                    \"\"\",\n",
            "                    },\n",
            "                    {\n",
            "                        \"role\": \"assistant\",\n",
            "                        \"content\": f\"{row['Simplified sentence']}\",\n",
            "                    },\n",
            "                ]\n",
            "            )\n",
            "        else:\n",
            "            reduced_difficulty = {\n",
            "                \"A1\": \"A1\",\n",
            "                \"A2\": \"A1\",\n",
            "                \"B1\": \"A2\",\n",
            "                \"B2\": \"B1\",\n",
            "                \"C1\": \"B2\",\n",
            "                \"C2\": \"C1\",\n",
            "                \"level1\": \"level1\",\n",
            "                \"level2\": \"level1\",\n",
            "                \"level3\": \"level2\",\n",
            "                \"level4\": \"level3\",\n",
            "            }\n",
            "            conversation.append(\n",
            "                {\n",
            "                    \"role\": \"user\",\n",
            "                    \"content\": f\"\"\"Voici une phrase en français de niveau {row['Difficulty']} à simplifier :\n",
            "                    \\\"\\\"\\\"{row['Sentence']}\\\"\\\"\\\"\n",
            "                    Donne moi une phrase simplifiée au niveau {reduced_difficulty[row['Difficulty']]} tout en conservant au maximum son sens original\n",
            "                    \"\"\",\n",
            "                }\n",
            "            )\n",
            "\n",
            "        return conversation\n",
            "\n",
            "    # Create dataset\n",
            "    logging.info(\"Create dataset...\")\n",
            "    conversation_list = (\n",
            "        df.reset_index()\n",
            "        .apply(create_conversation, axis=1)\n",
            "        .rename(\"conversation\")\n",
            "        .to_list()\n",
            "    )\n",
            "    dataset = Dataset.from_dict({\"chat\": conversation_list})\n",
            "\n",
            "    # Format dataset\n",
            "    logging.info(\"Format dataset...\")\n",
            "    formatted_dataset = dataset.map(\n",
            "        lambda x: {\n",
            "            \"formatted_chat\": tokenizer.apply_chat_template(\n",
            "                x[\"chat\"], tokenize=False, add_generation_prompt=True\n",
            "            )\n",
            "        }\n",
            "    )\n",
            "\n",
            "    return formatted_dataset\n",
            "\n",
            "\n",
            "# import"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 8,
         "metadata": {},
         "outputs": [
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "INFO:root:Create conversation...\n",
                  "INFO:root:Create dataset...\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "INFO:root:Format dataset...\n"
               ]
            },
            {
               "data": {
                  "application/vnd.jupyter.widget-view+json": {
                     "model_id": "09a0414a18cb48ae9081e616e96d89e6",
                     "version_major": 2,
                     "version_minor": 0
                  },
                  "text/plain": [
                     "Map:   0%|          | 0/125 [00:00<?, ? examples/s]"
                  ]
               },
               "metadata": {},
               "output_type": "display_data"
            },
            {
               "data": {
                  "text/plain": [
                     "'<s>[INST] <<SYS>>\\nVous êtes un modèle de langage naturel capable de simplifier des phrases en français. La phrase simplifiée doit avoir un sens aussi proche que possible de la phrase originale, mais elle est d\\'un niveau inférieur du CECRL et donc plus facile à comprendre. Par exemple, si une phrase est au niveau C1 du CECRL, simplifiez-la en B2. Si elle se situe au niveau B2, simplifiez-la en B1. Si elle se situe au niveau B1, simplifiez-la en A2. Si le niveau A2 est atteint, simplifiez en A1.\\n<</SYS>>\\n\\nVoici une phrase en français de niveau CECRL A2 à simplifier :\\n                    \"\"\"L\\'apprentissage des langues étrangères stimule les connexions neuronales.\"\"\"\\n                    Donne moi une phrase simplifiée au niveau CECRL A1 tout en conservant au maximum son sens original [/INST] On apprend mieux avec les langues étrangères. </s>'"
                  ]
               },
               "metadata": {},
               "output_type": "display_data"
            }
         ],
         "source": [
            "dataset = format_data(df, tokenizer, training=True)\n",
            "display(dataset[\"formatted_chat\"][0])"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### Tokenize the dataset"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 9,
         "metadata": {},
         "outputs": [],
         "source": [
            "# ------------------------------ ENCODE DATASET ------------------------------ #\n",
            "import torch\n",
            "from tqdm import notebook as notebook_tqdm\n",
            "\n",
            "\n",
            "def encode_dataset(dataset: Dataset, tokenizer: AutoTokenizer):\n",
            "    # Determine max length\n",
            "    logging.info(\"Determine max length...\")\n",
            "    max_length = max(\n",
            "        [\n",
            "            len(tokenizer.encode(chat))\n",
            "            for chat in notebook_tqdm.tqdm(dataset[\"formatted_chat\"])\n",
            "        ]\n",
            "    )\n",
            "\n",
            "    # Encode dataset\n",
            "    logging.info(\"Encode dataset...\")\n",
            "    encoded_dataset = dataset.map(\n",
            "        lambda x: tokenizer(\n",
            "            x[\"formatted_chat\"],\n",
            "            padding=\"max_length\",\n",
            "            truncation=True,\n",
            "            max_length=max_length,\n",
            "            return_attention_mask=True,\n",
            "        ),\n",
            "        batched=True,\n",
            "    )\n",
            "\n",
            "    # Create labels\n",
            "    logging.info(\"Create labels...\")\n",
            "    encoded_dataset = encoded_dataset.map(\n",
            "        lambda x: {\n",
            "            \"labels\": x[\"input_ids\"],\n",
            "            \"input_ids\": x[\"input_ids\"],\n",
            "            \"attention_mask\": x[\"attention_mask\"],\n",
            "        },\n",
            "        batched=True,\n",
            "    )\n",
            "\n",
            "    # Create dataset ready for training\n",
            "    logging.info(\"Create dataset ready for training...\")\n",
            "    encoded_dataset = Dataset.from_dict(\n",
            "        {\n",
            "            \"input_ids\": torch.tensor(encoded_dataset[\"input_ids\"]),\n",
            "            \"attention_mask\": torch.tensor(encoded_dataset[\"attention_mask\"]),\n",
            "            \"labels\": torch.tensor(encoded_dataset[\"labels\"]),\n",
            "        }\n",
            "    )\n",
            "\n",
            "    # Set format\n",
            "    encoded_dataset.set_format(\n",
            "        type=\"torch\",\n",
            "        columns=[\"input_ids\", \"attention_mask\", \"labels\"],\n",
            "    )\n",
            "\n",
            "    return encoded_dataset\n",
            "\n",
            "\n",
            "# import"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 10,
         "metadata": {},
         "outputs": [
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "INFO:root:Determine max length...\n"
               ]
            },
            {
               "data": {
                  "application/vnd.jupyter.widget-view+json": {
                     "model_id": "869b50a775fb4bf5955aa7f968e86cce",
                     "version_major": 2,
                     "version_minor": 0
                  },
                  "text/plain": [
                     "  0%|          | 0/125 [00:00<?, ?it/s]"
                  ]
               },
               "metadata": {},
               "output_type": "display_data"
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "INFO:root:Encode dataset...\n"
               ]
            },
            {
               "data": {
                  "application/vnd.jupyter.widget-view+json": {
                     "model_id": "cd0156939b2740af9b97b9977bc29d43",
                     "version_major": 2,
                     "version_minor": 0
                  },
                  "text/plain": [
                     "Map:   0%|          | 0/125 [00:00<?, ? examples/s]"
                  ]
               },
               "metadata": {},
               "output_type": "display_data"
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "INFO:root:Create labels...\n"
               ]
            },
            {
               "data": {
                  "application/vnd.jupyter.widget-view+json": {
                     "model_id": "ae4780a849fc4b5f81492f4df13676c4",
                     "version_major": 2,
                     "version_minor": 0
                  },
                  "text/plain": [
                     "Map:   0%|          | 0/125 [00:00<?, ? examples/s]"
                  ]
               },
               "metadata": {},
               "output_type": "display_data"
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "INFO:root:Create dataset ready for training...\n"
               ]
            },
            {
               "data": {
                  "text/plain": [
                     "Dataset({\n",
                     "    features: ['input_ids', 'attention_mask', 'labels'],\n",
                     "    num_rows: 125\n",
                     "})"
                  ]
               },
               "execution_count": 10,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "encoded_dataset = encode_dataset(dataset, tokenizer)\n",
            "encoded_dataset"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 11,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "application/vnd.jupyter.widget-view+json": {
                     "model_id": "effb8f8383054cd18c51781e628b0652",
                     "version_major": 2,
                     "version_minor": 0
                  },
                  "text/plain": [
                     "Map:   0%|          | 0/125 [00:00<?, ? examples/s]"
                  ]
               },
               "metadata": {},
               "output_type": "display_data"
            },
            {
               "data": {
                  "text/plain": [
                     "</s></s></s></s></s>    124\n",
                     "<s><s> [INST] <<SYS>      1\n",
                     "Name: count, dtype: int64"
                  ]
               },
               "metadata": {},
               "output_type": "display_data"
            },
            {
               "data": {
                  "application/vnd.jupyter.widget-view+json": {
                     "model_id": "643a7bcff6114769935cd43a3919806b",
                     "version_major": 2,
                     "version_minor": 0
                  },
                  "text/plain": [
                     "Map:   0%|          | 0/125 [00:00<?, ? examples/s]"
                  ]
               },
               "metadata": {},
               "output_type": "display_data"
            },
            {
               "data": {
                  "text/plain": [
                     "count    125.0\n",
                     "mean     334.0\n",
                     "std        0.0\n",
                     "min      334.0\n",
                     "25%      334.0\n",
                     "50%      334.0\n",
                     "75%      334.0\n",
                     "max      334.0\n",
                     "dtype: float64"
                  ]
               },
               "execution_count": 11,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "# Decode dataset\n",
            "display(\n",
            "    pd.Series(\n",
            "        encoded_dataset.map(\n",
            "            lambda e: {\"deencoded\": tokenizer.decode(e[\"input_ids\"])},\n",
            "            remove_columns=[\"input_ids\", \"attention_mask\", \"labels\"],\n",
            "        )[\"deencoded\"]\n",
            "    )\n",
            "    .apply(lambda x: x[:20])\n",
            "    .value_counts()\n",
            ")\n",
            "\n",
            "pd.Series(\n",
            "    encoded_dataset.map(\n",
            "        lambda e: {\"size\": len(e[\"input_ids\"])},\n",
            "        remove_columns=[\"input_ids\", \"attention_mask\", \"labels\"],\n",
            "    )[\"size\"]\n",
            ").astype(int).describe()"
         ]
      }
   ],
   "metadata": {
      "kernelspec": {
         "display_name": ".venv",
         "language": "python",
         "name": "python3"
      },
      "language_info": {
         "codemirror_mode": {
            "name": "ipython",
            "version": 3
         },
         "file_extension": ".py",
         "mimetype": "text/x-python",
         "name": "python",
         "nbconvert_exporter": "python",
         "pygments_lexer": "ipython3",
         "version": "3.9.13"
      }
   },
   "nbformat": 4,
   "nbformat_minor": 2
}
