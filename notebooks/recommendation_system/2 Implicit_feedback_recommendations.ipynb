{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate LingoRank with Collaborative Filtering models\n",
    "\n",
    "This notebook is used to fit collaborative filtering models (for implicit feedback) to the LingoRank data.\n",
    "\n",
    "The data should be prepared with the notebook 'RecommanderData'. The current notebook works if we already have CSV files in 'results/recommendation'.\n",
    "\n",
    "We also compute the metrics for the MovieLens-100k dataset to get a comparison.\n",
    "\n",
    "### Data preparation\n",
    "\n",
    "#### LingoRank\n",
    "\n",
    "The data is prepared following three strategies (1,2,3) (refer to 'RecommanderData' notebook). We will use strategies 2 and 3 (1 doesn't have enough data).\n",
    "\n",
    "We constitute a train set and a test set ensuring the following conditions:\n",
    "\n",
    "- Each user and each article should appear at least once in the training data\n",
    "- ~ 15% of the ratings are used for testing\n",
    "\n",
    "This if formulated as an optimization problem to split with respect to the constraints.\n",
    "\n",
    "#### ml-100k\n",
    "\n",
    "We use one of the predifined train/test split available in the released data (First train/test split).\n",
    "We remove in the test set the items that are not in the train set.\n",
    "All users are already in the train set.\n",
    "\n",
    "We consider a rating of 4 or more as positive and less than 4 as negative.\n",
    "\n",
    "### Evaluation strategy\n",
    "\n",
    "We follow the idea used in https://arxiv.org/abs/2305.02182\n",
    "\n",
    "For each item in the test set, we sample 4 negative samples. We use the model to rank these items and compute MRR@3 and NDCG@3.\n",
    "\n",
    "### Models\n",
    "\n",
    "#### Implicit feedback\n",
    "\n",
    "- ALS\n",
    "- BPR \n",
    "- LMF\n",
    "\n",
    "#### Explicit feedback (ml-100k only)\n",
    "\n",
    "- SVD \n",
    "\n",
    "#### Random\n",
    "\n",
    "- Rank the list of items randomly, not using any model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.sparse as sparse\n",
    "import implicit\n",
    "from tqdm.notebook import tqdm\n",
    "from random import shuffle\n",
    "from pulp import PULP_CBC_CMD\n",
    "from surprise import SVD, Reader, Dataset\n",
    "from pulp import LpProblem, LpVariable, lpSum, LpBinary, LpMaximize\n",
    "import random\n",
    "\n",
    "my_seed = 2023\n",
    "random.seed(my_seed)\n",
    "np.random.seed(my_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ml_100k(strategy: str):\n",
    "    # Load data into pandas DataFrames\n",
    "    train_df = pd.read_csv(\"https://files.grouplens.org/datasets/movielens/ml-100k/u1.base\", sep=\"\\t\", names=[\"userId\", \"itemId\", \"rating\", \"timestamp\"])\n",
    "    test_df = pd.read_csv(\"https://files.grouplens.org/datasets/movielens/ml-100k/u1.test\", sep=\"\\t\", names=[\"userId\", \"itemId\", \"rating\", \"timestamp\"])\n",
    "\n",
    "    # Find items in test_df but not in train_df\n",
    "    missing_items = set(test_df.itemId) - set(train_df.itemId)\n",
    "\n",
    "    # Count of these items\n",
    "    # num_missing_items = len(missing_items)\n",
    "\n",
    "    # print(\"Number of items in test_df but not in train_df:\", num_missing_items)\n",
    "    # print(\"Number of items in test_df:\", len(set(test_df.itemId)))\n",
    "\n",
    "    # Filtering out rows in test_df where itemId is in missing_items\n",
    "    test_df = test_df[~test_df.itemId.isin(missing_items)]\n",
    "\n",
    "    # Print the updated length of test_df\n",
    "    # print(\"Updated number of items in test_df:\", len(set(test_df.itemId)))\n",
    "\n",
    "    if strategy==\"explicit\":\n",
    "        reader = Reader(line_format=\"user item rating\", sep=\"\\t\", rating_scale=(train_df[\"rating\"].min(), train_df[\"rating\"].max()))\n",
    "\n",
    "        # Load the filtered data using Surprise's Dataset.load_from_df()\n",
    "        train_data = Dataset.load_from_df(train_df[[\"userId\", \"itemId\", \"rating\"]], reader=reader)\n",
    "        train_set = train_data.build_full_trainset()\n",
    "\n",
    "        # predictions_set = train_set.build_anti_testset() #all pairs (u, i) that are NOT in the training set.\n",
    "\n",
    "        test_set = list(zip(test_df[\"userId\"], test_df[\"itemId\"], test_df[\"rating\"]))\n",
    "\n",
    "        return train_df, test_df, train_set, test_set\n",
    "    \n",
    "    elif strategy==\"implicit\":\n",
    "        train_df.loc[train_df['rating'] < 4, 'rating'] = 0\n",
    "\n",
    "        # Create mapping for userIds and itemIds based on train_df\n",
    "        unique_userIds = train_df['userId'].unique()\n",
    "        unique_itemIds = train_df['itemId'].unique()\n",
    "\n",
    "        userId_mapping = {userId: i for i, userId in enumerate(unique_userIds)}\n",
    "        itemId_mapping = {itemId: i for i, itemId in enumerate(unique_itemIds)}\n",
    "\n",
    "        # Map userIds and itemIds in train_df to new consecutive IDs\n",
    "        train_df['mapped_userId'] = train_df['userId'].map(userId_mapping)\n",
    "        train_df['mapped_itemId'] = train_df['itemId'].map(itemId_mapping)\n",
    "\n",
    "        # Function to map new IDs in test_df and update the mapping accordingly\n",
    "        def map_and_update_id(id_value, current_mapping):\n",
    "            if id_value not in current_mapping:\n",
    "                current_mapping[id_value] = max(current_mapping.values()) + 1\n",
    "            return current_mapping[id_value]\n",
    "\n",
    "        test_df['mapped_userId'] = test_df['userId'].apply(lambda x: map_and_update_id(x, userId_mapping))\n",
    "        test_df['mapped_itemId'] = test_df['itemId'].apply(lambda x: map_and_update_id(x, itemId_mapping))\n",
    "\n",
    "        return train_df, test_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(data, test_size_ratio=0.25, tolerance=0.1):\n",
    "    # Initialize the optimization problem\n",
    "    prob = LpProblem(\"TrainTestSplit\", LpMaximize)\n",
    "\n",
    "    # Create binary variables for each rating\n",
    "    ratings_vars = LpVariable.dicts(\"Rating\", data.index.tolist(), cat=LpBinary)\n",
    "\n",
    "    # Add the objective function\n",
    "    prob += lpSum([ratings_vars[i] for i in data.index])\n",
    "\n",
    "    # Add the constraints\n",
    "    target_test_size = test_size_ratio * len(data)\n",
    "    prob += lpSum([ratings_vars[i] for i in data.index]) >= target_test_size - tolerance * len(data)\n",
    "    prob += lpSum([ratings_vars[i] for i in data.index]) <= target_test_size + tolerance * len(data)\n",
    "\n",
    "    for user_id in data['user_id'].unique():\n",
    "        user_ratings = data[data['user_id'] == user_id].index.tolist()\n",
    "        prob += lpSum([ratings_vars[i] for i in user_ratings]) <= len(user_ratings) - 1\n",
    "\n",
    "    for article_id in data['article_id'].unique():\n",
    "        article_ratings = data[data['article_id'] == article_id].index.tolist()\n",
    "        prob += lpSum([ratings_vars[i] for i in article_ratings]) <= len(article_ratings) - 1\n",
    "\n",
    "    # Solve the optimization problem\n",
    "    # status = prob.solve()\n",
    "    status = prob.solve(PULP_CBC_CMD(msg=0))\n",
    "\n",
    "    # Extract the train and test sets\n",
    "    train_data = data.loc[[i for i in data.index if ratings_vars[i].value() == 0]]\n",
    "    test_data = data.loc[[i for i in data.index if ratings_vars[i].value() == 1]]\n",
    "\n",
    "    return train_data, test_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_LingoRank(strategy: int):\n",
    "    data_full = pd.read_csv(f\"../results/recommendation/strategy{strategy}.csv\")\n",
    "    \n",
    "    ## Remove the articles for which there is no positive rating \n",
    "    # Before removing articles, count the unique articles\n",
    "    original_unique_articles = data_full['article_id'].nunique()\n",
    "\n",
    "    # Identify articles that have maximum rating <= 0\n",
    "    articles_to_remove = data_full.groupby('article_id')['rating'].max()\n",
    "    articles_to_remove = articles_to_remove[articles_to_remove <= 0].index.tolist()\n",
    "\n",
    "    # Remove these articles from data_full\n",
    "    data_full = data_full[~data_full['article_id'].isin(articles_to_remove)]\n",
    "\n",
    "    # After removing articles, count the unique articles\n",
    "    # remaining_unique_articles = data_full['article_id'].nunique()\n",
    "\n",
    "    # Calculate and print the number of removed articles\n",
    "    # num_removed_articles = original_unique_articles - remaining_unique_articles\n",
    "    # print(\"Number of removed articles:\", num_removed_articles)\n",
    "\n",
    "    data = data_full[(data_full['rating'] != 0)].copy()\n",
    "    \n",
    "    unique_user_ids = data['user_id'].unique()\n",
    "    unique_article_ids = data['article_id'].unique()\n",
    "\n",
    "    user_id_mapping = {user_id: i for i, user_id in enumerate(unique_user_ids)}\n",
    "    article_id_mapping = {article_id: i for i, article_id in enumerate(unique_article_ids)}\n",
    "\n",
    "    # Map user_ids and article_ids to new consecutive IDs using loc\n",
    "    data.loc[:, 'mapped_user_id'] = data['user_id'].map(user_id_mapping)\n",
    "    data.loc[:, 'mapped_article_id'] = data['article_id'].map(article_id_mapping)\n",
    "\n",
    "    # data_full = data_full.copy() # Avoid SettingWithCopyWarning\n",
    "\n",
    "    data_full.loc[:, 'mapped_user_id'] = data_full['user_id'].map(user_id_mapping)\n",
    "    data_full.loc[:, 'mapped_article_id'] = data_full['article_id'].map(article_id_mapping)\n",
    "\n",
    "    train_data, test_data = train_test_split(data)\n",
    "    print(f\"Strategy {strategy} - Proportion of positive ratings affected to test set: {round(len(test_data)/(len(test_data)+len(train_data))*100,2)} %\")\n",
    "\n",
    "    return data_full, data, train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strategy 2 - Proportion of positive ratings affected to test set: 15.66 %\n",
      "Strategy 3 - Proportion of positive ratings affected to test set: 15.97 %\n"
     ]
    }
   ],
   "source": [
    "datasets = {}\n",
    "\n",
    "# 1. LingoRank\n",
    "datasets['LingoRank'] = {}\n",
    "datasets['LingoRank']['strategies'] = {}\n",
    "for i in range(2,4):\n",
    "    datasets['LingoRank']['strategies'][i] = {}\n",
    "    datasets['LingoRank']['strategies'][i]['data_full'], datasets['LingoRank']['strategies'][i]['data'], datasets['LingoRank']['strategies'][i]['train_data'], datasets['LingoRank']['strategies'][i]['test_data'] = load_LingoRank(i)\n",
    "\n",
    "# 2. MovieLens-100k\n",
    "datasets['ml-100k'] = {}\n",
    "datasets['ml-100k']['strategies'] = {}\n",
    "\n",
    "datasets['ml-100k']['strategies']['explicit'] = {}\n",
    "datasets['ml-100k']['strategies']['implicit'] = {}\n",
    "\n",
    "datasets['ml-100k']['strategies']['explicit']['train_df'], datasets['ml-100k']['strategies']['explicit']['test_df'], datasets['ml-100k']['strategies']['explicit']['train_set'], datasets['ml-100k']['strategies']['explicit']['test_set'] = load_ml_100k('explicit')\n",
    "datasets['ml-100k']['strategies']['implicit']['train_df'], datasets['ml-100k']['strategies']['implicit']['test_df'] = load_ml_100k('implicit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(set(train_data.user_id))>=len(set(test_data.user_id)))\n",
    "# print(set(test_data['article_id']).issubset(set(train_data['article_id'])))\n",
    "# print(len(set(train_data.user_id)))\n",
    "# print(len(set(test_data.user_id)))\n",
    "# print(len(set(train_data['article_id'])))\n",
    "# print(len(set(test_data['article_id'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create user-item sparse matrix\n",
    "# 1. Lingorank\n",
    "for key, strategy in datasets['LingoRank']['strategies'].items():\n",
    "    strategy['user_item_train_data'] = sparse.csr_matrix(\n",
    "        (strategy['train_data']['rating'].astype(float), (strategy['train_data']['mapped_user_id'], strategy['train_data']['mapped_article_id']))\n",
    "    )\n",
    "\n",
    "# 2. ml-100k (implicit)\n",
    "strategy = datasets['ml-100k']['strategies']['implicit']\n",
    "strategy['user_item_train_data'] = sparse.csr_matrix(\n",
    "    (strategy['train_df']['rating'].astype(float), (strategy['train_df']['mapped_userId'], strategy['train_df']['mapped_itemId']))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebe6797e5f7c45358ea2af32f3b2042a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Datasets:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35aeefb7432844a796d3ae46aa20d2b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Strategies:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anonymous/miniforge3/envs/Lingorank/lib/python3.9/site-packages/implicit/cpu/als.py:95: RuntimeWarning: OpenBLAS is configured to use 10 threads. It is highly recommended to disable its internal threadpool by setting the environment variable 'OPENBLAS_NUM_THREADS=1' or by calling 'threadpoolctl.threadpool_limits(1, \"blas\")'. Having OpenBLAS use a threadpool can lead to severe performance issues here.\n",
      "  check_blas_config()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20dec8bd94364fe0b1a5846bd78c425c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fitting models:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6e0db9e18984bbdbfc6e25c7bbae058",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4fee05080d441518710b02329a4482c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1da9f55a8aa447d4bbdd4700d12cfef5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "901a6cbe984f4c7b8b09c12d722b09ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fitting models:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04a6681c0bc64ac98714c29090ba23c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd163998b87a48fd899eb50ea3b352e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f74a4d4d6a046b79f25d15caaefe58c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2d76a7a50e7438188eb6b03e05f1f44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Strategies:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4af90120d1a418a923f3f54750542ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fitting models:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f37d11ea29d644719ed8bbea897312a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1ae740bcb1e41008abde2261388bbae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e8533e5c9e746e6ac523e6dc3f5b219",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x122d9ad00>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for key_dataset, dataset in tqdm(datasets.items(), desc=\"Datasets\"):\n",
    "    for key, strategy in tqdm(dataset['strategies'].items(), desc=\"Strategies\"):\n",
    "\n",
    "        if key==\"explicit\":\n",
    "            continue #Need other specific model\n",
    "        # Create a dictionary of models\n",
    "        strategy['models'] = {\n",
    "            \"ALS\": implicit.als.AlternatingLeastSquares(factors=50, random_state=my_seed),\n",
    "            \"BPR\": implicit.bpr.BayesianPersonalizedRanking(factors=50, random_state=my_seed),\n",
    "            \"LMF\": implicit.lmf.LogisticMatrixFactorization(factors=50, random_state=my_seed)\n",
    "        }\n",
    "\n",
    "        # Fit each model with a tqdm progress bar\n",
    "        for name in tqdm(strategy['models'].keys(), desc=\"Fitting models\"):\n",
    "            if name==\"ALS\":\n",
    "                alpha = 40\n",
    "                training_data = (strategy['user_item_train_data'] * alpha).astype('double')\n",
    "            else:\n",
    "                # Convert data to binary preference matrix\n",
    "                training_data = (strategy['user_item_train_data'] >= 1).astype('double')\n",
    "            strategy['models'][name].fit(training_data)\n",
    "\n",
    "        strategy['models'][\"random\"]=\"random\" #Add a fake model that will be use to compute metrics\n",
    "\n",
    "strategy = datasets['ml-100k']['strategies']['explicit']\n",
    "strategy['models'] = {}\n",
    "strategy['models']['SVD'] = SVD(random_state=my_seed)\n",
    "strategy['models']['SVD'].fit(strategy['train_set'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LingoRank\n",
      "  strategies\n",
      "    2\n",
      "      data_full\n",
      "      data\n",
      "      train_data\n",
      "      test_data\n",
      "      user_item_train_data\n",
      "      models\n",
      "        ALS\n",
      "        BPR\n",
      "        LMF\n",
      "        random\n",
      "    3\n",
      "      data_full\n",
      "      data\n",
      "      train_data\n",
      "      test_data\n",
      "      user_item_train_data\n",
      "      models\n",
      "        ALS\n",
      "        BPR\n",
      "        LMF\n",
      "        random\n",
      "ml-100k\n",
      "  strategies\n",
      "    explicit\n",
      "      train_df\n",
      "      test_df\n",
      "      train_set\n",
      "      test_set\n",
      "      models\n",
      "        SVD\n",
      "    implicit\n",
      "      train_df\n",
      "      test_df\n",
      "      user_item_train_data\n",
      "      models\n",
      "        ALS\n",
      "        BPR\n",
      "        LMF\n",
      "        random\n"
     ]
    }
   ],
   "source": [
    "# Display the structure of our dict\n",
    "def display_keys(d, indent=0):\n",
    "    for key, value in d.items():\n",
    "        print('  ' * indent + str(key))\n",
    "        if isinstance(value, dict):\n",
    "            display_keys(value, indent+1)\n",
    "\n",
    "display_keys(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ndcg_at_k(ranked_list, k):\n",
    "    \"\"\"\n",
    "    Compute NDCG at rank k\n",
    "    \"\"\"\n",
    "    dcg = sum((2 ** rel - 1) / np.log2(idx + 2) for idx, rel in enumerate(ranked_list[:k]))\n",
    "    idcg = sum((2 ** rel - 1) / np.log2(idx + 2) for idx, rel in enumerate(sorted(ranked_list, reverse=True)[:k]))\n",
    "    return dcg / idcg if idcg > 0 else 0\n",
    "\n",
    "def mrr_at_k(ranked_list, k):\n",
    "    \"\"\"\n",
    "    Compute MRR at rank k\n",
    "    \"\"\"\n",
    "    for idx, rel in enumerate(ranked_list[:k]):\n",
    "        if rel > 0:\n",
    "            return 1 / (idx + 1)\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(test_df, data_full, model, dataset, k=3):\n",
    "    \n",
    "    ndcgs = []\n",
    "    mrrs = []\n",
    "    \n",
    "    # Group by user and filter positive and negative items\n",
    "    if dataset==\"LingoRank\":\n",
    "        groupByKey = \"mapped_user_id\"\n",
    "    elif dataset==\"ml-100k\" and isinstance(model,SVD):\n",
    "        groupByKey = \"userId\"\n",
    "    else:\n",
    "        groupByKey = \"mapped_userId\"\n",
    "    grouped = test_df.groupby(groupByKey)\n",
    "    for user, group in tqdm(grouped, desc=\"Evaluating users\"):\n",
    "        \n",
    "        if dataset==\"ml-100k\" and isinstance(model,SVD):\n",
    "            positive_items = group[group[\"rating\"] >= 4][\"itemId\"].values\n",
    "            negative_items = group[group[\"rating\"] < 4][\"itemId\"].values\n",
    "        elif dataset==\"ml-100k\":\n",
    "            positive_items = group[group[\"rating\"] >= 4][\"mapped_itemId\"].values\n",
    "            negative_items = group[group[\"rating\"] < 4][\"mapped_itemId\"].values\n",
    "        else:\n",
    "            positive_items = group[\"mapped_article_id\"].values\n",
    "            negative_items = data_full[(data_full['mapped_user_id'] == user) & (data_full['rating'] == 0)].mapped_article_id.to_list() # Will return all the articles but usefull to proceed like that if we have a strategy for which zeros are clearly defined\n",
    "        \n",
    "        if len(positive_items) == 0 or len(negative_items) == 0:\n",
    "            # print(f\"Skip user with ID {user}\")\n",
    "            continue  # Skip if no positive or negative items\n",
    "        \n",
    "        # Select one positive item and four negative items\n",
    "        positive_item = np.random.choice(positive_items)\n",
    "        sampled_negative_items = np.random.choice(negative_items, size=min(4, len(negative_items)), replace=False)\n",
    "\n",
    "        if len(sampled_negative_items)<4:\n",
    "            # print(f\"Sample negative items is {len(sampled_negative_items)} for user {user}\")\n",
    "            continue # Skip if we cannot constitute a list of 5\n",
    "            \n",
    "        \n",
    "        # Candidate list of 5 items\n",
    "        candidate_items = list(sampled_negative_items) + [positive_item]\n",
    "        \n",
    "        if model==\"random\":\n",
    "            predictions = list(range(5))\n",
    "            shuffle(predictions)\n",
    "        elif isinstance(model,SVD):\n",
    "            predictions = [model.predict(user, item).est for item in candidate_items]\n",
    "        else:\n",
    "            item_factors = model.item_factors\n",
    "            user_factors = model.user_factors\n",
    "            predictions = [np.dot(user_factors[user], item_factors[item]) for item in candidate_items]\n",
    "            \n",
    "        # Rank the items based on predicted ratings\n",
    "        ranked_items = [1 if item == positive_item else 0 for _, item in sorted(zip(predictions, candidate_items), reverse=True)]\n",
    "        \n",
    "        # Calculate NDCG@3 and MRR@3\n",
    "        ndcg = ndcg_at_k(ranked_items, k)\n",
    "        mrr = mrr_at_k(ranked_items, k)\n",
    "        \n",
    "        ndcgs.append(ndcg)\n",
    "        mrrs.append(mrr)\n",
    "\n",
    "    avg_ndcg = np.mean(ndcgs)\n",
    "    avg_mrr = np.mean(mrrs)\n",
    "    return avg_ndcg, avg_mrr, ndcgs, mrrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5c42bb7cd5f45b08d31971675d5b378",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Datasets:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d3b2546b51a43d2ba40eaf9a5dd337e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Strategies:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d3df6e30fef4f9bae731beff02f4039",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Models for strategy 2:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9111476f8ec74ea692bea015dfae77f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating users:   0%|          | 0/1140 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a56d1c024c164a3f9d8b0bb4ce2ca39f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating users:   0%|          | 0/1140 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8407ec19322f40d9995f75d85ca7a84f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating users:   0%|          | 0/1140 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3dea2b7af154da0b68db703e43a9e9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating users:   0%|          | 0/1140 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc084a3af1b944e8b68bc6f4390f2495",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Models for strategy 3:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abdbcf0850bb427a82103963a04cadc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating users:   0%|          | 0/1098 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d57c26a072a4dac9bc76e7e307c16b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating users:   0%|          | 0/1098 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fb42b1aa69243408e8e1d0c4e7ae0ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating users:   0%|          | 0/1098 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63f9731744f44e09826ec40a91e24cac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating users:   0%|          | 0/1098 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25d520aece5843729575ca2b0f67d2ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Strategies:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a6572c6d669401bb4ad20c80aafc56d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Models for strategy explicit:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59b02ad7516d41c3a945b798830026ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating users:   0%|          | 0/459 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8daee69a28294788a5499e9762d55786",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Models for strategy implicit:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81cfa217ff464c3297529a292f3dd76b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating users:   0%|          | 0/459 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd67a2251f364db9989fcf8c864b7356",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating users:   0%|          | 0/459 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "906db9467a7d48abb752f25115f3edb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating users:   0%|          | 0/459 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d44d31a2872467f99ced63955e00995",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating users:   0%|          | 0/459 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for key_dataset, dataset in tqdm(datasets.items(), desc=\"Datasets\"):\n",
    "    for key, strategy in tqdm(dataset['strategies'].items(), desc=\"Strategies\"):\n",
    "\n",
    "        # Dictionary to store evaluation metrics\n",
    "        strategy['evaluation_results'] = {}\n",
    "        # Evaluate each model and store the results in the evaluation_results dictionary\n",
    "        for name, model in tqdm(strategy['models'].items(), desc=f\"Models for strategy {key}\"):\n",
    "            if key_dataset==\"LingoRank\":\n",
    "                test_data = strategy['test_data']\n",
    "                data_full = strategy['data_full']\n",
    "            elif key_dataset==\"ml-100k\":\n",
    "                test_data = strategy['test_df']\n",
    "                data_full = None\n",
    "            avg_ndcg, avg_mrr, ndcgs, mrrs = evaluate(test_data, data_full, model, key_dataset,k=3)\n",
    "            strategy['evaluation_results'][name] = {\n",
    "                \"NDCG@3\": avg_ndcg,\n",
    "                \"MRR@3\": avg_mrr,\n",
    "                \"All_NDCGs\": ndcgs,\n",
    "                \"All_MRRs\": mrrs\n",
    "            }\n",
    "\n",
    "        # print(\"=\"*50)\n",
    "        # print(f\"Strategy {key}\")\n",
    "        # print(\"=\"*50)\n",
    "        # # Print the evaluation results in a structured manner\n",
    "        # for name, metrics in strategy['evaluation_results'].items():\n",
    "            \n",
    "        #     print(f\"Results for {name}:\")\n",
    "        #     print(f\"NDCG@3: {metrics['NDCG@3']:.4f}\")\n",
    "        #     print(f\"MRR@3: {metrics['MRR@3']:.4f}\")\n",
    "        #     print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_d2dcd_row1_col0, #T_d2dcd_row1_col1, #T_d2dcd_row1_col2, #T_d2dcd_row1_col3, #T_d2dcd_row1_col4, #T_d2dcd_row5_col0, #T_d2dcd_row5_col1, #T_d2dcd_row5_col2, #T_d2dcd_row5_col3, #T_d2dcd_row5_col4, #T_d2dcd_row8_col0, #T_d2dcd_row8_col1, #T_d2dcd_row8_col2, #T_d2dcd_row8_col3, #T_d2dcd_row8_col4, #T_d2dcd_row10_col0, #T_d2dcd_row10_col1, #T_d2dcd_row10_col2, #T_d2dcd_row10_col3, #T_d2dcd_row10_col4 {\n",
       "  background-color: lightblue;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_d2dcd\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_d2dcd_level0_col0\" class=\"col_heading level0 col0\" >dataset</th>\n",
       "      <th id=\"T_d2dcd_level0_col1\" class=\"col_heading level0 col1\" >strategy</th>\n",
       "      <th id=\"T_d2dcd_level0_col2\" class=\"col_heading level0 col2\" >model</th>\n",
       "      <th id=\"T_d2dcd_level0_col3\" class=\"col_heading level0 col3\" >NDCG@3</th>\n",
       "      <th id=\"T_d2dcd_level0_col4\" class=\"col_heading level0 col4\" >MRR@3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_d2dcd_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_d2dcd_row0_col0\" class=\"data row0 col0\" >LingoRank</td>\n",
       "      <td id=\"T_d2dcd_row0_col1\" class=\"data row0 col1\" >2</td>\n",
       "      <td id=\"T_d2dcd_row0_col2\" class=\"data row0 col2\" >ALS</td>\n",
       "      <td id=\"T_d2dcd_row0_col3\" class=\"data row0 col3\" >0.424492</td>\n",
       "      <td id=\"T_d2dcd_row0_col4\" class=\"data row0 col4\" >0.376901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d2dcd_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_d2dcd_row1_col0\" class=\"data row1 col0\" >LingoRank</td>\n",
       "      <td id=\"T_d2dcd_row1_col1\" class=\"data row1 col1\" >2</td>\n",
       "      <td id=\"T_d2dcd_row1_col2\" class=\"data row1 col2\" >BPR</td>\n",
       "      <td id=\"T_d2dcd_row1_col3\" class=\"data row1 col3\" >0.561544</td>\n",
       "      <td id=\"T_d2dcd_row1_col4\" class=\"data row1 col4\" >0.492398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d2dcd_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_d2dcd_row2_col0\" class=\"data row2 col0\" >LingoRank</td>\n",
       "      <td id=\"T_d2dcd_row2_col1\" class=\"data row2 col1\" >2</td>\n",
       "      <td id=\"T_d2dcd_row2_col2\" class=\"data row2 col2\" >LMF</td>\n",
       "      <td id=\"T_d2dcd_row2_col3\" class=\"data row2 col3\" >0.464300</td>\n",
       "      <td id=\"T_d2dcd_row2_col4\" class=\"data row2 col4\" >0.416959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d2dcd_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_d2dcd_row3_col0\" class=\"data row3 col0\" >LingoRank</td>\n",
       "      <td id=\"T_d2dcd_row3_col1\" class=\"data row3 col1\" >2</td>\n",
       "      <td id=\"T_d2dcd_row3_col2\" class=\"data row3 col2\" >random</td>\n",
       "      <td id=\"T_d2dcd_row3_col3\" class=\"data row3 col3\" >0.415347</td>\n",
       "      <td id=\"T_d2dcd_row3_col4\" class=\"data row3 col4\" >0.357018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d2dcd_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_d2dcd_row4_col0\" class=\"data row4 col0\" >LingoRank</td>\n",
       "      <td id=\"T_d2dcd_row4_col1\" class=\"data row4 col1\" >3</td>\n",
       "      <td id=\"T_d2dcd_row4_col2\" class=\"data row4 col2\" >ALS</td>\n",
       "      <td id=\"T_d2dcd_row4_col3\" class=\"data row4 col3\" >0.420522</td>\n",
       "      <td id=\"T_d2dcd_row4_col4\" class=\"data row4 col4\" >0.368549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d2dcd_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_d2dcd_row5_col0\" class=\"data row5 col0\" >LingoRank</td>\n",
       "      <td id=\"T_d2dcd_row5_col1\" class=\"data row5 col1\" >3</td>\n",
       "      <td id=\"T_d2dcd_row5_col2\" class=\"data row5 col2\" >BPR</td>\n",
       "      <td id=\"T_d2dcd_row5_col3\" class=\"data row5 col3\" >0.548513</td>\n",
       "      <td id=\"T_d2dcd_row5_col4\" class=\"data row5 col4\" >0.481633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d2dcd_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_d2dcd_row6_col0\" class=\"data row6 col0\" >LingoRank</td>\n",
       "      <td id=\"T_d2dcd_row6_col1\" class=\"data row6 col1\" >3</td>\n",
       "      <td id=\"T_d2dcd_row6_col2\" class=\"data row6 col2\" >LMF</td>\n",
       "      <td id=\"T_d2dcd_row6_col3\" class=\"data row6 col3\" >0.488481</td>\n",
       "      <td id=\"T_d2dcd_row6_col4\" class=\"data row6 col4\" >0.435641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d2dcd_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_d2dcd_row7_col0\" class=\"data row7 col0\" >LingoRank</td>\n",
       "      <td id=\"T_d2dcd_row7_col1\" class=\"data row7 col1\" >3</td>\n",
       "      <td id=\"T_d2dcd_row7_col2\" class=\"data row7 col2\" >random</td>\n",
       "      <td id=\"T_d2dcd_row7_col3\" class=\"data row7 col3\" >0.407176</td>\n",
       "      <td id=\"T_d2dcd_row7_col4\" class=\"data row7 col4\" >0.352004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d2dcd_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_d2dcd_row8_col0\" class=\"data row8 col0\" >ml-100k</td>\n",
       "      <td id=\"T_d2dcd_row8_col1\" class=\"data row8 col1\" >explicit</td>\n",
       "      <td id=\"T_d2dcd_row8_col2\" class=\"data row8 col2\" >SVD</td>\n",
       "      <td id=\"T_d2dcd_row8_col3\" class=\"data row8 col3\" >0.656278</td>\n",
       "      <td id=\"T_d2dcd_row8_col4\" class=\"data row8 col4\" >0.599074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d2dcd_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_d2dcd_row9_col0\" class=\"data row9 col0\" >ml-100k</td>\n",
       "      <td id=\"T_d2dcd_row9_col1\" class=\"data row9 col1\" >implicit</td>\n",
       "      <td id=\"T_d2dcd_row9_col2\" class=\"data row9 col2\" >ALS</td>\n",
       "      <td id=\"T_d2dcd_row9_col3\" class=\"data row9 col3\" >0.583889</td>\n",
       "      <td id=\"T_d2dcd_row9_col4\" class=\"data row9 col4\" >0.521759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d2dcd_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_d2dcd_row10_col0\" class=\"data row10 col0\" >ml-100k</td>\n",
       "      <td id=\"T_d2dcd_row10_col1\" class=\"data row10 col1\" >implicit</td>\n",
       "      <td id=\"T_d2dcd_row10_col2\" class=\"data row10 col2\" >BPR</td>\n",
       "      <td id=\"T_d2dcd_row10_col3\" class=\"data row10 col3\" >0.604823</td>\n",
       "      <td id=\"T_d2dcd_row10_col4\" class=\"data row10 col4\" >0.546296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d2dcd_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_d2dcd_row11_col0\" class=\"data row11 col0\" >ml-100k</td>\n",
       "      <td id=\"T_d2dcd_row11_col1\" class=\"data row11 col1\" >implicit</td>\n",
       "      <td id=\"T_d2dcd_row11_col2\" class=\"data row11 col2\" >LMF</td>\n",
       "      <td id=\"T_d2dcd_row11_col3\" class=\"data row11 col3\" >0.558990</td>\n",
       "      <td id=\"T_d2dcd_row11_col4\" class=\"data row11 col4\" >0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d2dcd_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_d2dcd_row12_col0\" class=\"data row12 col0\" >ml-100k</td>\n",
       "      <td id=\"T_d2dcd_row12_col1\" class=\"data row12 col1\" >implicit</td>\n",
       "      <td id=\"T_d2dcd_row12_col2\" class=\"data row12 col2\" >random</td>\n",
       "      <td id=\"T_d2dcd_row12_col3\" class=\"data row12 col3\" >0.403600</td>\n",
       "      <td id=\"T_d2dcd_row12_col4\" class=\"data row12 col4\" >0.342130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x122efcac0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Extracting evaluation results\n",
    "data = []\n",
    "\n",
    "for dataset_key, dataset in datasets.items():\n",
    "    for strategy_num, strategy_data in dataset['strategies'].items():\n",
    "        for model_name, results in strategy_data['evaluation_results'].items():\n",
    "            row = {\n",
    "                'dataset': dataset_key,\n",
    "                'strategy': strategy_num,\n",
    "                'model': model_name,\n",
    "                'NDCG@3': results['NDCG@3'],\n",
    "                'MRR@3': results['MRR@3']\n",
    "            }\n",
    "            data.append(row)\n",
    "\n",
    "# Convert to DataFrame\n",
    "evaluation_results = pd.DataFrame(data)\n",
    "\n",
    "def highlight_best(row):\n",
    "    \"\"\"Highlight the entire row in light blue if the best NDCG@3 value also has the best MRR@3 value.\"\"\"\n",
    "    subset = evaluation_results[(evaluation_results['dataset'] == row['dataset']) & (evaluation_results['strategy'] == row['strategy'])]\n",
    "    max_ndcg = subset['NDCG@3'].max()\n",
    "    max_mrr = subset['MRR@3'].max()\n",
    "    if row['NDCG@3'] == max_ndcg and row['MRR@3'] == max_mrr:\n",
    "        return ['background-color: lightblue']*5\n",
    "    return ['']*5\n",
    "\n",
    "styled_evaluation_results = evaluation_results.style.apply(highlight_best, axis=1)\n",
    "\n",
    "display(styled_evaluation_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Lingorank",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
